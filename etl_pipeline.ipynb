{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data has been updated'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlalchemy\n",
    "from sqlalchemy.exc import IntegrityError\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "from datetime import datetime, timedelta\n",
    "from pytz import timezone\n",
    "# Passwords and API keys\n",
    "import Keys\n",
    "\n",
    "def extracting_and_loading_data(list_of_cities):\n",
    "    connection_string = create_connection_string()\n",
    "    # start mysql server and create tables\n",
    "    cities_df = get_cities_data(list_of_cities)\n",
    "    cities_to_db = transform_cities_df(cities_df)\n",
    "    push_unique_data_to_db(cities_to_db, 'cities', connection_string)\n",
    "    cities_from_sql = extract_from_db('cities', connection_string)\n",
    "    population_to_db = transform_population(cities_df, cities_from_sql)\n",
    "    push_unique_data_to_db(population_to_db, 'population', connection_string)\n",
    "    weather_df = get_weather_data(cities_from_sql)\n",
    "    push_data_to_db(weather_df, 'weather', connection_string)\n",
    "    airports_df = get_airports_data(cities_from_sql)\n",
    "    airports_to_db = transform_airports_df(airports_df)\n",
    "    push_unique_data_to_db(airports_to_db, 'airports', connection_string)\n",
    "    airports_from_sql = extract_from_db('airports', connection_string)\n",
    "    flights_df = get_flights_data(airports_from_sql)\n",
    "    push_data_to_db(flights_df, 'flights', connection_string)\n",
    "    return \"Data has been updated\"\n",
    "\n",
    "def get_cities_data(cities):\n",
    "  cities_data = []\n",
    "\n",
    "  for city in cities:\n",
    "    city_data = {}\n",
    "\n",
    "    # city\n",
    "    city_data[\"City\"] = city\n",
    "\n",
    "    # create the soup\n",
    "    url = f\"https://www.wikipedia.org/wiki/{city}\"\n",
    "    response = requests.get(url)\n",
    "    city_soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # country\n",
    "    city_data[\"Country\"] = city_soup.find(class_=\"infobox-data\").get_text()\n",
    "\n",
    "    # population\n",
    "    city_population = city_soup.find(string=\"Population\").find_next(\"td\").get_text()\n",
    "    try:\n",
    "      city_population_clean = int(city_population.replace(\",\", \"\"))\n",
    "    except (ValueError):\n",
    "      city_population_clean = int('0')\n",
    "    city_data[\"Population\"] = city_population_clean\n",
    "\n",
    "    # data retrieved\n",
    "    city_data[\"Year_Data_Retrieved\"] = city_soup.find(string=\"Population\").find_next().get_text()[2:6]\n",
    "\n",
    "    # latitude and longitude\n",
    "    city_data[\"Latitude\"] = city_soup.find(class_=\"latitude\").get_text()\n",
    "    city_data[\"Longitude\"] = city_soup.find(class_=\"longitude\").get_text()\n",
    "\n",
    "    # append this city's data to the cities list\n",
    "    cities_data.append(city_data)\n",
    "\n",
    "  return pd.DataFrame(cities_data)\n",
    "\n",
    "def create_connection_string():\n",
    "  schema = \"gans_local\"\n",
    "  host = \"localhost\" # \"127.0.0.1\"\n",
    "  user = \"root\"\n",
    "  password = Keys.MySQL_pass\n",
    "  port = 3306\n",
    "  return f'mysql+pymysql://{user}:{password}@{host}:{port}/{schema}'\n",
    "\n",
    "def dms_to_decimal(dms):\n",
    "    import re\n",
    "    \n",
    "    # Regex to extract degrees, minutes, seconds, and hemisphere\n",
    "    pattern = r\"(\\d+)°(\\d+)?′?(\\d+)?″?([NSEW])\"\n",
    "    match = re.match(pattern, dms.strip())\n",
    "    \n",
    "    if not match:\n",
    "        raise ValueError(f\"Invalid DMS format: {dms}\")\n",
    "    \n",
    "    # Extract parts\n",
    "    degrees = float(match.group(1))\n",
    "    minutes = float(match.group(2)) if match.group(2) else 0.0\n",
    "    seconds = float(match.group(3)) if match.group(3) else 0.0\n",
    "    hemisphere = match.group(4).upper()\n",
    "    \n",
    "    # Convert to decimal degrees\n",
    "    decimal_degrees = degrees + (minutes / 60) + (seconds / 3600)\n",
    "    \n",
    "    # Adjust for southern/western hemispheres\n",
    "    if hemisphere in ('S', 'W'):\n",
    "        decimal_degrees = -decimal_degrees\n",
    "    \n",
    "    return decimal_degrees\n",
    "\n",
    "def transform_cities_df(cities_df):\n",
    "  cities_to_db = cities_df[[\"City\", \"Country\", \"Latitude\", \"Longitude\"]].rename(columns={\"City\": \"City_name\"})\n",
    "  cities_to_db[\"Latitude\"] = cities_to_db[\"Latitude\"].apply(dms_to_decimal)\n",
    "  cities_to_db[\"Longitude\"] = cities_to_db[\"Longitude\"].apply(dms_to_decimal)\n",
    "  return cities_to_db\n",
    "\n",
    "def push_unique_data_to_db(dataframe, table_name, connection_string):\n",
    "    engine = create_engine(connection_string)\n",
    "    # Get column names from the DataFrame\n",
    "    columns = list(dataframe.columns)\n",
    "    column_placeholders = \", \".join([\"%s\"] * len(columns))\n",
    "    column_names = \", \".join(columns)\n",
    "\n",
    "    # Prepare the SQL query\n",
    "    sql_query = f\"\"\"\n",
    "        INSERT IGNORE INTO {table_name} ({column_names})\n",
    "        VALUES ({column_placeholders});\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute the query for each row\n",
    "    with engine.connect() as conn:\n",
    "        for _, row in dataframe.iterrows():\n",
    "            conn.execute(sql_query, tuple(row))\n",
    "    # print(f\"Data inserted into {table_name} successfully (if not already present).\")\n",
    "\n",
    "def extract_from_db(table_name, connection_string):\n",
    "  df = pd.read_sql(table_name, con=connection_string)\n",
    "  return df\n",
    "\n",
    "def transform_population(cities_df, cities_from_sql):\n",
    "  population_df = cities_df[[\"Population\", \"Year_Data_Retrieved\", \"City\"]].rename(columns={\"City\": \"City_name\"})\n",
    "  # Merge with cities_from_sql to get the correct City_id\n",
    "  population_to_db = population_df.merge(\n",
    "      cities_from_sql,\n",
    "      on=[\"City_name\"],\n",
    "      how=\"left\",\n",
    "      suffixes=(\"\", \"_db\")\n",
    "  )\n",
    "  # Keep only the necessary columns for the population table\n",
    "  population_to_db = population_to_db[[\"Population\", \"Year_Data_Retrieved\", \"City_id\"]]\n",
    "  return population_to_db\n",
    "\n",
    "def get_weather_data(cities_df):\n",
    "  berlin_timezone = timezone('Europe/Berlin')\n",
    "  API_key = Keys.OpenWeather_API_key\n",
    "  cities_weather_data = []\n",
    "\n",
    "  for city_index in cities_df.index:\n",
    "    city_id = cities_df.loc[city_index,'City_id']\n",
    "    lat = cities_df.loc[city_index,'Latitude']\n",
    "    lon = cities_df.loc[city_index,'Longitude']\n",
    "\n",
    "    # Reference the parameters in the url.\n",
    "    url = (f\"https://api.openweathermap.org/data/2.5/forecast?lat={lat}&lon={lon}&appid={API_key}&units=metric\")\n",
    "    response = requests.get(url)\n",
    "    weather_json = response.json()\n",
    "\n",
    "    retrieval_time = datetime.now(berlin_timezone).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    for item in weather_json['list']:\n",
    "      city_weather_data = {\n",
    "        'city_id': city_id,\n",
    "        'forecast_time': item.get(\"dt_txt\"),\n",
    "        'temperature': item[\"main\"].get(\"temp\"),\n",
    "        'feels_like': item[\"main\"].get(\"feels_like\"),\n",
    "        'humidity': item[\"main\"].get(\"humidity\"),\n",
    "        'forecast_desc': item[\"weather\"][0].get(\"description\"),\n",
    "        'forecast': item[\"weather\"][0].get(\"main\"),\n",
    "        'wind_speed': item[\"wind\"].get(\"speed\"),\n",
    "        'rain_prob': item.get(\"rain\", {}).get(\"3h\", 0),\n",
    "        'station': weather_json[\"city\"].get(\"name\"),\n",
    "        'country_code': weather_json[\"city\"].get(\"country\"),\n",
    "        'data_retrieved_at': retrieval_time\n",
    "      }\n",
    "      cities_weather_data.append(city_weather_data)\n",
    "\n",
    "  weather_df = pd.DataFrame(cities_weather_data)\n",
    "  weather_df[\"forecast_time\"] = pd.to_datetime(weather_df[\"forecast_time\"])\n",
    "  weather_df[\"data_retrieved_at\"] = pd.to_datetime(weather_df[\"data_retrieved_at\"])\n",
    "\n",
    "  return weather_df\n",
    "\n",
    "def push_data_to_db(df, table_name, connection_string):\n",
    "  df.to_sql(table_name,\n",
    "            if_exists='append',\n",
    "            con=connection_string,\n",
    "            index=False)\n",
    "\n",
    "def get_airports_data(df):\n",
    "    list_for_df = []\n",
    "\n",
    "    # Loop through the rows of the input DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        url = \"https://aerodatabox.p.rapidapi.com/airports/search/location\"\n",
    "        querystring = {\n",
    "            \"lat\": row['Latitude'],\n",
    "            \"lon\": row['Longitude'],\n",
    "            \"radiusKm\": \"50\",\n",
    "            \"limit\": \"5\",\n",
    "            \"withFlightInfoOnly\": \"true\"\n",
    "        }\n",
    "        headers = {\n",
    "            \"X-RapidAPI-Host\": \"aerodatabox.p.rapidapi.com\",\n",
    "            \"X-RapidAPI-Key\": Keys.Rapid_API_key\n",
    "        }\n",
    "\n",
    "        # Make the API request\n",
    "        response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "        airports_data = pd.json_normalize(response.json().get('items', []))\n",
    "        airports_data['City_id'] = row['City_id']  # Add City_id for merging later\n",
    "        list_for_df.append(airports_data)\n",
    "    api_data = pd.concat(list_for_df, ignore_index=True)\n",
    "    # Merge the original DataFrame with the API results\n",
    "    merged_df = df.merge(api_data, on='City_id', how='left')\n",
    "    return merged_df\n",
    "\n",
    "def transform_airports_df(airports_df):\n",
    "  # Selecting only the columns we need\n",
    "  airports_to_db = airports_df[[\"icao\", \"iata\", \"name\", \"City_id\"]]\n",
    "  airports_to_db = airports_to_db.rename(columns={\"name\": \"Airport_name\"})\n",
    "  return airports_to_db\n",
    "\n",
    "def get_flights_data(airports_df):\n",
    "    api_key = Keys.Rapid_API_key\n",
    "\n",
    "    berlin_timezone = timezone('Europe/Berlin')\n",
    "    today = datetime.now(berlin_timezone).date()\n",
    "    tomorrow = (today + timedelta(days=1))\n",
    "\n",
    "    flight_items = []\n",
    "\n",
    "    for icao in airports_df[\"icao\"]:\n",
    "        # The API can only make 12-hour calls\n",
    "        times = [[\"00:00\", \"11:59\"], [\"12:00\", \"23:59\"]]\n",
    "\n",
    "        for time in times:\n",
    "            url = f\"https://aerodatabox.p.rapidapi.com/flights/airports/icao/{icao}/{tomorrow}T{time[0]}/{tomorrow}T{time[1]}\"\n",
    "\n",
    "            querystring = {\n",
    "                \"withLeg\": \"true\",\n",
    "                \"direction\": \"Arrival\",\n",
    "                \"withCancelled\": \"false\",\n",
    "                \"withCodeshared\": \"true\",\n",
    "                \"withCargo\": \"false\",\n",
    "                \"withPrivate\": \"false\"\n",
    "            }\n",
    "\n",
    "            headers = {\n",
    "                'x-rapidapi-host': \"aerodatabox.p.rapidapi.com\",\n",
    "                'x-rapidapi-key': api_key\n",
    "            }\n",
    "\n",
    "            try:\n",
    "                response = requests.get(url, headers=headers, params=querystring)\n",
    "\n",
    "                # Validate the response\n",
    "                if response.status_code == 200 and response.content.strip():\n",
    "                    try:\n",
    "                        flights_json = response.json()\n",
    "                    except ValueError as e:\n",
    "                        print(f\"Error decoding JSON for ICAO={icao}: {e}\")\n",
    "                        print(f\"Response Content: {response.content.decode('utf-8', errors='ignore')}\")\n",
    "                        continue\n",
    "                else:\n",
    "                    print(f\"API returned invalid response for ICAO={icao}: {response.status_code}\")\n",
    "                    print(f\"Response Content: {response.content.decode('utf-8', errors='ignore')}\")\n",
    "                    continue\n",
    "\n",
    "                retrieval_time = datetime.now(berlin_timezone).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                icao_id = airports_df.loc[airports_df[\"icao\"] == icao, \"icao\"].values[0]\n",
    "\n",
    "                for item in flights_json.get(\"arrivals\", []):\n",
    "                    flight_item = {\n",
    "                        \"arrival_airport_icao\": icao_id,\n",
    "                        \"departure_airport_icao\": item[\"departure\"][\"airport\"].get(\"icao\", None),\n",
    "                        \"departure_airport_name\": item[\"departure\"][\"airport\"].get(\"name\", None),\n",
    "                        \"scheduled_arrival_time\": item[\"arrival\"][\"scheduledTime\"].get(\"local\", None),\n",
    "                        \"flight_number\": item.get(\"number\", None),\n",
    "                        \"data_retrieved_at\": retrieval_time\n",
    "                    }\n",
    "\n",
    "                    flight_items.append(flight_item)\n",
    "\n",
    "            except requests.exceptions.RequestException as req_err:\n",
    "                print(f\"Request error for ICAO={icao}: {req_err}\")\n",
    "\n",
    "    flights_df = pd.DataFrame(flight_items)\n",
    "    flights_df[\"scheduled_arrival_time\"] = flights_df[\"scheduled_arrival_time\"].str[:-6]\n",
    "    flights_df[\"scheduled_arrival_time\"] = pd.to_datetime(flights_df[\"scheduled_arrival_time\"])\n",
    "    flights_df[\"data_retrieved_at\"] = pd.to_datetime(flights_df[\"data_retrieved_at\"])\n",
    "    \n",
    "    return flights_df\n",
    "\n",
    "extracting_and_loading_data([\"Berlin\", \"Hamburg\", \"Munich\", \"Cologne\", \"Stuttgart\", \"Leipzig\", \"Dortmund\", \"Vienna\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
